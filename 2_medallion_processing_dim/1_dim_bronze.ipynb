{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d0e86a9-4c01-4374-8d8a-bf1adee24bfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, TimestampType, FloatType\n",
    "\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db731a32-35c8-4345-8060-9ece41a26abe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_name='ecommerce'\n",
    "\n",
    "brand_schema = StructType([\n",
    "    StructField('brand_code', StringType(), False),\n",
    "    StructField('brand_name', StringType(), True),\n",
    "    StructField('category_code', StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86d5f8de-f8d7-4216-b69e-603a09b456f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_data_path='/Volumes/ecommerce/source_data/raw/brands/*.csv'\n",
    "\n",
    "df=spark.read.option('header','true').option('delimeter',',').schema(brand_schema).csv(raw_data_path)\n",
    "\n",
    "#add metadata columns\n",
    "df=df.withColumn(\"_source_file\", F.col(\"_metadata.file_path\")) \\\n",
    "     .withColumn('ingested_at', F.current_timestamp())\n",
    "    \n",
    "display(df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6957cc1d-b2b1-4faf-a9f5-4e1974f9da5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df.write.format('delta') \\\n",
    "    .mode('overwrite') \\\n",
    "    .option('mergeSchema','true') \\\n",
    "    .saveAsTable(f'{catalog_name}.bronze.brz_brands')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "290d694f-d6d8-45b9-ac3b-8f4dfd2aa3b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b771b93e-5ac7-44c1-9f7a-194d49d14d0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "category_schema = StructType([\n",
    "    StructField(\"category_code\", StringType(), False),\n",
    "    StructField(\"category_name\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Load data using the schema defined\n",
    "raw_data_path = \"/Volumes/ecommerce/source_data/raw/category/*.csv\"\n",
    "\n",
    "df_raw = spark.read.option(\"header\", \"true\").option(\"delimiter\", \",\").schema(category_schema).csv(raw_data_path)\n",
    "\n",
    "# Add metadata columns\n",
    "df_raw = df_raw.withColumn(\"_ingested_at\", F.current_timestamp()) \\\n",
    "               .withColumn(\"_source_file\", F.col(\"_metadata.file_path\"))\n",
    "\n",
    "\n",
    "# Write raw data to the Bronze layer (catalog: ecommerce, schema: bronze, table: brz_category)\n",
    "df_raw.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{catalog_name}.bronze.brz_category\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0edcc8d7-6053-42ec-9e36-510d63c36018",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "839bddd0-72eb-4774-a524-5d981c7a01c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "products_schema=StructType([\n",
    "    StructField('product_id', StringType(), False),\n",
    "    StructField('sku',StringType(), True),\n",
    "    StructField('category_code', StringType(), True),\n",
    "    StructField('brand_code',StringType(), True),\n",
    "    StructField('color',StringType(), True),\n",
    "    StructField('size',StringType(), True),\n",
    "    StructField('material',StringType(), True),\n",
    "    StructField('weight_grams',StringType(), True),\n",
    "    StructField('length_cm',StringType(), True),\n",
    "    StructField('width_cm', FloatType(), True),\n",
    "    StructField('height_cm',FloatType(), True),\n",
    "    StructField('rating_count',FloatType(), True)\n",
    "])\n",
    "\n",
    "raw_data_path = \"/Volumes/ecommerce/source_data/raw/products/*.csv\"\n",
    "\n",
    "df=spark.read.option('header','true').option('delimeter',',').schema(products_schema).csv(raw_data_path) \\\n",
    "    .withColumn('file_name', F.col('_metaData.file_path')) \\\n",
    "    .withColumn('ingest_timestamp', F.current_timestamp())\n",
    "\n",
    "df.write.format('delta') \\\n",
    "    .mode('overwrite') \\\n",
    "    .option('mergeSchema', 'true') \\\n",
    "    .saveAsTable(f'{catalog_name}.bronze.brz_products')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "878e3f84-358a-4310-b902-05be9c2b7bde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Customers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caaca806-2028-4f82-8481-e0e71f0d32bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customers_schema = StructType([\n",
    "    StructField(\"customer_id\", StringType(), False),\n",
    "    StructField(\"phone\", StringType(), True),\n",
    "    StructField(\"country_code\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Load data using the schema defined\n",
    "raw_data_path =\"/Volumes/ecommerce/source_data/raw/customers/*.csv\"\n",
    "\n",
    "df_raw = spark.read.option(\"header\", \"true\").option(\"delimiter\", \",\").schema(customers_schema).csv(raw_data_path) \\\n",
    "    .withColumn(\"file_name\", F.col(\"_metadata.file_path\")) \\\n",
    "    .withColumn(\"ingest_timestamp\", F.current_timestamp())\n",
    "\n",
    "# Write raw data to the Bronze layer (catalog: ecommerce, schema: bronze, table: brz_customers)\n",
    "df_raw.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{catalog_name}.bronze.brz_customers\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bf39f98-dc44-4d75-9a8f-ca3380590ab9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0850ccba-a842-4f67-84cf-c0b95442a8f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define schema for the data file\n",
    "date_schema = StructType([\n",
    "    StructField(\"date\", StringType(), True),           # Raw date in string format\n",
    "    StructField(\"year\", IntegerType(), True),          # Year\n",
    "    StructField(\"day_name\", StringType(), True),       # Day name (can be mixed case)\n",
    "    StructField(\"quarter\", IntegerType(), True),       # Quarter\n",
    "    StructField(\"week_of_year\", IntegerType(), True),  # Week of year (can be negative)\n",
    "])\n",
    "\n",
    "# Load data using the schema defined\n",
    "raw_data_path = f\"/Volumes/ecommerce/source_data/raw/date/*.csv\" \n",
    "\n",
    "df_raw = spark.read.option(\"header\", \"true\").option(\"delimiter\", \",\").schema(date_schema).csv(raw_data_path)\n",
    "\n",
    "# Add metadata columns\n",
    "df_raw = df_raw.withColumn(\"_ingested_at\", F.current_timestamp()) \\\n",
    "               .withColumn(\"_source_file\", F.col(\"_metadata.file_path\"))\n",
    "\n",
    "\n",
    "# Write raw data to the Bronze layer (catalog: ecommerce, schema: bronze, table: brz_calendar) \n",
    "df_raw.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{catalog_name}.bronze.brz_calendar\")      "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1_dim_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
